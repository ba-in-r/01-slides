---
title: "Unidad 10 ‚Äî Detecci√≥n de Anomal√≠as"
subtitle: "Semana 15: Outliers y Ley de Benford"
author: "Eduard F. Mart√≠nez Gonz√°lez"
---

<a href="mailto:efmartinez@icesi.edu.co" style="color:black;">
<img src="pic/correo.png" alt="Email" width="20" height="20"/> efmartinez@icesi.edu.co
</a>

<a href="https://github.com/eduard-martinez" style="color:black;"> 
<img src="pic/github.png" alt="Qries" width="20" height="20"/> eduard-martinez
</a>

<a href="https://twitter.com/emartigo" style="color:black;"> 
<img src="pic/twitter.jpg" alt="Qries" width="20" height="20"/> @emartigo
</a>

<a href="https://eduard-martinez.github.io" style="color:black;"> 
<img src="pic/link.png" alt="Qries" width="20" height="20"/> https://eduard-martinez.github.io
</a>

# ¬øQu√© es una anomal√≠a?

En an√°lisis de datos, una **anomal√≠a** (o *outlier*) es una observaci√≥n que se aleja significativamente del patr√≥n general del conjunto de datos. Detectar estas observaciones es clave, porque pueden revelar errores de registro, fen√≥menos raros o incluso fraudes.

Ejemplos t√≠picos:

- Un cliente con un cr√©dito inusualmente alto.  
- Un estudiante con una calificaci√≥n fuera del rango esperado.  
- Una transacci√≥n con un valor que no se ajusta al comportamiento habitual.

En Business Analytics, la detecci√≥n de anomal√≠as es un paso esencial del an√°lisis exploratorio de datos (EDA) y una herramienta fundamental para la gesti√≥n del riesgo y la auditor√≠a de datos.

## Tipos de anomal√≠as

1. **Univariadas:** afectan a una sola variable (por ejemplo, edad, monto, ingreso).  
2. **Multivariadas:** surgen de combinaciones inusuales entre variables (por ejemplo, clientes j√≥venes con cr√©ditos alt√≠simos).

En esta clase nos centraremos en las anomal√≠as univariadas, aquellas que pueden identificarse analizando cada variable individualmente.

# Aplicaci√≥n en R

En este ejercicio aplicaremos t√©cnicas de detecci√≥n de anomal√≠as sobre una base de datos que simula el comportamiento acad√©mico de un grupo de estudiantes. Cada observaci√≥n representa a un estudiante inscrito en un curso, e incluye variables relacionadas con su desempe√±o y participaci√≥n a lo largo del semestre.

En este contexto:

- Cada **estudiante** es una observaci√≥n.  
- Las **variables num√©ricas** incluyen indicadores como asistencia, participaci√≥n, trabajos, quizzes y proyecto final.  
- El **promedio final** refleja el desempe√±o global del estudiante.  
- Algunas observaciones presentan **valores at√≠picos o inconsistentes**, como notas negativas, valores mayores a 5 o combinaciones poco realistas (por ejemplo, alta asistencia pero promedio bajo).

El objetivo es aplicar un **an√°lisis exploratorio y estad√≠stico** que nos permita:

- Identificar visual y num√©ricamente **valores extremos**.  
- Comparar diferentes **m√©todos de detecci√≥n de outliers** (gr√°ficos, robustos y estad√≠sticos).  
- Reflexionar sobre c√≥mo estas anomal√≠as pueden afectar la interpretaci√≥n y calidad de los datos acad√©micos.

::: callout-tip
Este ejercicio replica una situaci√≥n real en la que un profesor detecta irregularidades en las calificaciones de su grupo.  
A partir de las herramientas estad√≠sticas vistas en clase, aprenderemos c√≥mo diagnosticar y documentar esos casos de manera objetiva.
:::

## Preparaci√≥n del entorno

Antes de comenzar, es importante asegurar que el entorno de trabajo est√© limpio, reproducible y con todas las librer√≠as necesarias cargadas.

1. **Limpiamos** el entorno para evitar conflictos con objetos previos.  
2. **Instalamos** (si es necesario) y **cargamos** los paquetes requeridos para la manipulaci√≥n, visualizaci√≥n y detecci√≥n de anomal√≠as.  
3. **Importamos** la base de datos simulada de notas estudiantiles, que contiene observaciones normales y algunas ‚Äúnotas raras‚Äù generadas intencionalmente.  
4. Exploramos la estructura y primeras filas de la base para familiarizarnos con su contenido.

```{webr-r}
## Limpiar el entorno de trabajo
rm(list = ls())

## Instalar paquetes (solo si es necesario)
if (!require("pacman")) {install.packages("pacman") ; require("pacman")}

## Cargar librer√≠as
p_load(tidyverse) # Manipulaci√≥n y visualizaci√≥n de datos
p_load(outliers)  # Pruebas Grubbs y Dixon
p_load(EnvStats)  # Test de Rosner
p_load(univOutl)  # Funciones integradas para IQR/MAD

## Fijar semilla para reproducibilidad
set.seed(123)
```

::: callout-note
`tidyverse`: Conjunto de paquetes dise√±ados para la manipulaci√≥n, transformaci√≥n y visualizaci√≥n de datos en R.  

`outliers`: Implementa pruebas estad√≠sticas cl√°sicas para detecci√≥n de valores at√≠picos, como *Grubbs* y *Dixon*, que permiten identificar observaciones extremas en una sola variable num√©rica.

`EnvStats`: Proporciona m√©todos avanzados de an√°lisis estad√≠stico, incluyendo la prueba de Rosner, ideal para detectar *m√∫ltiples outliers simult√°neamente en una muestra grande.

`univOutl`: Ofrece funciones integradas para aplicar distintos m√©todos robustos de detecci√≥n de outliers univariados, como el *IQR*, *MAD* o boxplots ajustados (`LocScaleB`, `boxB`), facilitando la comparaci√≥n entre t√©cnicas.
:::

## Ingesta de datos 

En esta secci√≥n realizamos la ingesta de datos. En este caso, trabajaremos con una base sint√©tica llamada **`notas`**, que representa el rendimiento acad√©mico de un grupo de estudiantes a lo largo del semestre. Cada registro corresponde a un estudiante e incluye variables relacionadas con su desempe√±o, participaci√≥n y h√°bitos de estudio. Algunos registros fueron generados con valores an√≥malos intencionalmente (notas imposibles, inconsistencias o valores fuera de rango), con el fin de practicar su identificaci√≥n.

La estructura de las variables es la siguiente:

- **`asistencia`** ‚Üí proporci√≥n de clases asistidas (0‚Äì1).  
- **`participacion`** ‚Üí nivel de participaci√≥n en clase (0‚Äì5).  
- **`trabajos`** ‚Üí promedio de calificaciones en trabajos entregados (0‚Äì5).  
- **`quiz_1`, `quiz_2`** ‚Üí notas obtenidas en los dos quizzes del curso (0‚Äì5).  
- **`proyecto_final`** ‚Üí nota final del proyecto (0‚Äì5).  
- **`promedio`** ‚Üí calificaci√≥n global del estudiante (ponderaci√≥n de los componentes anteriores).  
- **`grupo`** ‚Üí d√≠a o cohorte al que pertenece el estudiante (por ejemplo, ‚ÄúViernes‚Äù o ‚ÄúMartes‚Äù).  
- **`id_estudiante`** ‚Üí identificador √∫nico de cada estudiante.

Nuestro objetivo ser√° **identificar observaciones que se desv√≠en del patr√≥n general**, como: notas fuera del rango esperado (menores que 0 o mayores que 5); comportamientos incoherentes (alta asistencia con bajo promedio); casos extremos que podr√≠an reflejar errores de registro o comportamientos at√≠picos reales.

```{webr-r}
#| warning: false
#| message: false

## generar los datos
source("https://raw.githubusercontent.com/ba-in-r/01-slides/main/week-15/data/week-15.r")

## check data
print("listo")
```

## Exploratory Data Analysis (EDA)

Antes de aplicar pruebas estad√≠sticas, el primer paso es **visualizar** y **resumir** los datos.  Esto nos permite entender la distribuci√≥n de una variable y detectar visualmente valores at√≠picos. **Objetivos del EDA:**

- Explorar la forma de la distribuci√≥n.  
- Identificar asimetr√≠as, colas largas o valores extremos.  
- Calcular estad√≠sticas descriptivas b√°sicas: Medidas de tendencia central (media, mediana); Medidas de dispersi√≥n (rango, desviaci√≥n est√°ndar, IQR); Medidas de forma (asimetr√≠a y curtosis).

```{webr-r}
## Vista previa
glimpse(notas)
summary(notas)
```

### Visualizaci√≥n de anomal√≠as

El an√°lisis gr√°fico es el punto de partida. Para empezar, utilizaremos histogramas y boxplots que nos ayuden a visualizar la dispersi√≥n de las notas y detectar gr√°ficamente los posibles valores at√≠picos.

```{webr-r}
# Histograma del promedio final
ggplot(notas, aes(x = promedio)) +
geom_histogram(bins = 15, fill = "steelblue", color = "black", alpha = 0.7) +
theme_bw()
```

El histograma permite observar la forma de la distribuci√≥n de las notas: si es sim√©trica, sesgada o multimodal. En contextos educativos, una ligera asimetr√≠a positiva (muchos aprobados, pocos reprobados) es com√∫n. Las barras aisladas en los extremos pueden representar notas at√≠picas o errores de registro (por ejemplo, valores negativos o mayores que 5).

```{webr-r}
# Boxplot general de notas
ggplot(notas, aes(y = promedio)) +
geom_boxplot(fill = "purple", color = "black", alpha = 0.5, outlier.color = "red") +
theme_bw()
```

La caja representa el rango intercuart√≠lico (IQR), donde se concentra el 50 % central de las notas. La l√≠nea central dentro de la caja indica la mediana (valor t√≠pico o m√°s frecuente). Los puntos rojos marcan las observaciones que se encuentran fuera de los l√≠mites esperados (outliers). En este caso, corresponden a estudiantes con un desempe√±o excepcionalmente bajo o alto, o posiblemente a errores en el registro.
  
## M√©todos de detecci√≥n

Una vez explorada la distribuci√≥n de los datos, pasamos a la detecci√≥n sistem√°tica de anomal√≠as mediante diferentes enfoques. Cada m√©todo tiene supuestos y ventajas distintas: algunos se basan en reglas estad√≠sticas, otros en medidas robustas que resisten la influencia de outliers. En esta secci√≥n aplicaremos cinco estrategias complementarias para detectar valores at√≠picos en la variable `promedio`.

### Percentiles

Una forma simple de detectar valores extremos es comparar los datos con umbrales percentilares, por ejemplo, el **1%** y el **99%**. Las observaciones fuera de ese rango se consideran inusuales.

```{webr-r}
## Percentiles 1% y 99%
quantiles <- quantile(notas$promedio, probs = c(0.01, 0.99), na.rm = TRUE)
quantiles

## Filtrar posibles outliers
notas_q <- filter(notas , promedio < quantiles[1] | promedio > quantiles[2])
summary(notas_q)
```

### Z-Score

El Z-Score mide cu√°ntas desviaciones est√°ndar se encuentra cada valor respecto a la media. Por convenci√≥n, se consideran at√≠picos los valores con (|Z| > 3).
  
```{webr-r}
## Calcular Z-Score 
notas <- mutate(notas , z_score = scale(promedio))

## Filtrar valores extremos
notas_z <- filter(notas , abs(z_score) > 3)
summary(notas_z)
```

::: callout-note
El m√©todo Z-Score funciona bien cuando la variable tiene una distribuci√≥n aproximadamente normal. En distribuciones sesgadas (como suele ocurrir en notas o ingresos), puede marcar falsos positivos.
:::

###  Rango intercuart√≠lico (IQR)

El m√©todo del rango intercuart√≠lico (IQR) es una versi√≥n robusta del boxplot tradicional. Define umbrales con base en los cuartiles ($Q_1$) y ($Q_3$): $\text{L√≠mite inferior} = Q_1 - 1.5 \times IQR \quad ; \quad \text{L√≠mite superior} = Q_3 + 1.5 \times IQR$

```{webr-r}
## Detectar outliers con IQR
boxB(notas$promedio, method = "resistant")
```

::: callout-note
El IQR es menos sensible a la forma de la distribuci√≥n y se usa ampliamente en entornos de negocio y educaci√≥n. Sin embargo, su desempe√±o disminuye si la variable es altamente asim√©trica.
:::

###  MAD / M√©todo de Hampel

El MAD (Median Absolute Deviation) calcula la desviaci√≥n absoluta respecto a la mediana, y el m√©todo de Hampel lo utiliza para establecer l√≠mites de detecci√≥n. Este enfoque es robusto y muy eficaz en datos con colas pesadas o valores extremos localizados.

```{webr-r}
## Detecci√≥n de outliers mediante MAD
LocScaleB(notas$promedio, method = "MAD")
```

::: callout-note
El MAD se considera uno de los m√©todos m√°s estables frente a outliers severos. diferencia del Z-Score, no asume normalidad y es adecuado para variables como notas, ingresos o montos financieros.
:::

###  RRMS (Varianza robusta)

El m√©todo RRMS (Robust Root Mean Square) utiliza estimadores robustos de varianza para identificar observaciones que se alejan significativamente del centro de la distribuci√≥n, considerando tanto colas superiores como inferiores.

```{webr-r}
## Detecci√≥n robusta con RRMS
out_RRMS <- hotspots::outliers(notas$promedio, tail = "both")
summary(out_RRMS)
plot(out_RRMS)
```

::: callout-note
El RRMS combina la precisi√≥n estad√≠stica del Z-Score con la resistencia del MAD. Es √∫til cuando queremos una detecci√≥n autom√°tica que mantenga consistencia en diferentes variables.
:::

### Comparaci√≥n de m√©todos

Cada m√©todo de detecci√≥n de anomal√≠as parte de una **l√≥gica distinta** sobre qu√© significa ser ‚Äúinusual‚Äù. Algunos se basan en medidas cl√°sicas (media y desviaci√≥n est√°ndar), otros en estimadores robustos (mediana y MAD) que son menos sensibles a valores extremos. La siguiente tabla resume las caracter√≠sticas m√°s importantes de los principales m√©todos vistos en clase:

| **M√©todo**        | **Supuesto principal**              | **Robustez** | **Cu√°ndo usar** |
|--------------------|------------------------------------|---------------|------------------|
| **Percentiles**    | Ninguno                            | Media         | Exploraci√≥n inicial o cribado r√°pido. |
| **Z-Score**        | Normalidad de los datos            | Baja          | Datos sim√©tricos y previamente escalados. |
| **IQR (Tukey)**    | Cuartiles representativos          | Media         | Distribuciones moderadamente asim√©tricas. |
| **MAD / Hampel**   | Mediana estable y colas largas     | Alta          | Datos con colas pesadas o presencia de outliers fuertes. |
| **RRMS**           | Estimador robusto de varianza      | Alta          | Identificaci√≥n autom√°tica de extremos en grandes muestras. |


## Pruebas estad√≠sticas

Hasta ahora hemos explorado m√©todos descriptivos y robustos para identificar posibles outliers. Sin embargo, en algunos contextos ‚Äîpor ejemplo, auditor√≠as, evaluaci√≥n de calidad o estudios cient√≠ficos‚Äî se requiere una validaci√≥n estad√≠stica formal que determine si un valor extremo es significativamente distinto al resto de los datos. Para ello utilizamos pruebas estad√≠sticas que formulan hip√≥tesis y se basan en el c√°lculo de un **p-value**:

| **Prueba** | **Uso principal** | **Tama√±o de muestra** | **Outliers detectables** |
|-------------|------------------|------------------------|---------------------------|
| **Grubbs test** | Detecci√≥n de un solo outlier en muestras grandes. | n > 25 | 1 |
| **Dixon test** | Detecci√≥n de un outlier en muestras peque√±as. | 3 ‚â§ n ‚â§ 25 | 1 |
| **Rosner test** | Detecci√≥n simult√°nea de m√∫ltiples outliers. | n ‚â• 25 | k (varios) |

### Grubbs Test

La **prueba de Grubbs** eval√∫a si el valor m√°s extremo (m√°ximo o m√≠nimo) de la muestra se diferencia significativamente del resto. 

**Hip√≥tesis:** 

- $H_0: \text{No hay outliers en la muestra}$ 
- $H_A: \text{El valor m√°s extremo es un outlier}$

**Interpretaci√≥n del p-value:** Si `p-value < 0.05`, se **rechaza H‚ÇÄ** ‚Üí el valor extremo se considera un *outlier* estad√≠sticamente significativo. Si `p-value ‚â• 0.05`, no hay evidencia suficiente para considerarlo at√≠pico.

```{webr-r}
## Ejemplo de prueba de Grubbs sobre las notas promedio
grubbs.test(notas$promedio)
```

### Dixon Test

La prueba de Dixon tambi√©n busca detectar un √∫nico valor at√≠pico, pero est√° dise√±ada para muestras peque√±as (3‚Äì25 observaciones). Compara la diferencia entre el valor m√°s extremo y su vecino m√°s cercano con el rango total.

**Hip√≥tesis:** 

- $H_0: \text{Todos los valores provienen de la misma poblaci√≥n.}$ 
- $H_A: \text{Existe un valor at√≠pico (el m√°s alto o el m√°s bajo).}$

**Interpretaci√≥n del p-value:** Si `p-value < 0.05`, el valor extremo se considera outlier. Si `p-value ‚â• 0.05`, no se considera significativamente diferente.

```{webr-r}
## Ejemplo de aplicaci√≥n con una muestra peque√±a
dixon.test(sample(notas$promedio, 20))
```

### Rosner Test

La prueba de Rosner permite detectar varios outliers al mismo tiempo. A diferencia de las anteriores, esta prueba es iterativa: elimina los valores extremos uno por uno, recalculando la media y la desviaci√≥n est√°ndar tras cada iteraci√≥n.

**Hip√≥tesis:** 

- $H_0: \text{No hay outliers en la muestra.}$ 

- $H_A: H_A: \text{Hasta } k \text{ observaciones son outliers.}$

Interpretaci√≥n:

	‚Ä¢	La prueba calcula un conjunto de estad√≠sticos ( $R_i$ ) y valores cr√≠ticos ( $\lambda_i$ ).
	‚Ä¢	Si ( $R_i$ > $\lambda_i$), la observaci√≥n correspondiente se clasifica como outlier.
	‚Ä¢	El n√∫mero final de outliers detectados depender√° del par√°metro $k$ (cantidad m√°xima a evaluar).

```{webr-r}
## Ejemplo con detecci√≥n m√∫ltiple
rosnerTest(notas$promedio, k = 5, alpha = 0.05)
```

::: callout-tip
El p-value mide la evidencia contra la hip√≥tesis nula ($H_0$). Un valor peque√±o (por debajo de 0.05) indica que el valor extremo es poco probable bajo el patr√≥n normal de los datos. En otras palabras, mientras menor el p-value, m√°s probable es que la observaci√≥n sea realmente un outlier.
:::

## Ley de Benford

La Ley de Benford, tambi√©n conocida como la Ley del Primer D√≠gito, describe un patr√≥n sorprendente en muchos conjuntos de datos reales: los n√∫meros que comienzan con d√≠gitos peque√±os (1, 2 o 3) aparecen con mucha m√°s frecuencia que los que comienzan con 8 o 9. En lugar de una distribuci√≥n uniforme (donde cada d√≠gito tendr√≠a 11,1 % de probabilidad), la Ley de Benford predice que el d√≠gito 1 aparecer√° aproximadamente el 30 % de las veces, el 2 un 17 %, y as√≠ sucesivamente, decreciendo logar√≠tmicamente.

$P(d) = \log_{10}(1 + \frac{1}{d})$

### ¬øPor qu√© es √∫til?

Este patr√≥n se cumple en datos naturales, financieros o econ√≥micos que no han sido manipulados manualmente. Por ello, la Ley de Benford se utiliza ampliamente en: auditor√≠a y detecci√≥n de fraudes financieros; Verificaci√≥n de integridad de bases de datos; An√°lisis de reportes contables y registros p√∫blicos. Cuando los datos se desv√≠an significativamente de la ley, puede indicar errores de registro o manipulaci√≥n intencional.

### Condiciones para aplicar la Ley de Benford

Antes de aplicar la ley, la variable debe cumplir ciertas condiciones:

1. Ser num√©rica y positiva.  
2. No tener l√≠mites fijos (por ejemplo, 0‚Äì100 o 1‚Äì5).  
3. Presentar varios √≥rdenes de magnitud (es decir, amplitud suficiente entre el valor m√≠nimo y el m√°ximo).  
4. No estar redondeada artificialmente o expresada en porcentajes.  

### Evaluaci√≥n previa de magnitud

El primer paso es verificar si la variable cumple con los criterios de magnitud. Para esto se calculan dos indicadores: `OOM` (Order of Magnitude): logaritmo de la raz√≥n entre el valor m√°ximo y el m√≠nimo. `ROM` (Robust Order of Magnitude): logaritmo de la raz√≥n entre los percentiles 99 y 1. Si ambos son mayores que 3, la Ley de Benford puede aplicarse de manera confiable.

# Actividad en clase

	‚Ä¢	En grupos, aplicar tres m√©todos de detecci√≥n a una variable.
	‚Ä¢	Comparar resultados y discutir cu√°l m√©todo es m√°s confiable.
	‚Ä¢	Relacionar resultados con casos reales (fraude, errores de captura, comportamiento an√≥malo).

## Instrucciones:

1. Ejecute los *chunks* de c√≥digo proporcionados en R (puede hacerlo directamente en el navegador o en RStudio).  
2. Observe los resultados obtenidos en cada secci√≥n.  
3. Genere un documento en Word (.docx) donde:  
   - Copie las preguntas que aparecen al final.  
   - Redacte sus interpretaciones y conclusiones con base en los resultados.  
   - **No copie el c√≥digo**, solo redacte sus respuestas.  
4. Suba su documento y su **script en R** a la plataforma **Intu**, en la actividad correspondiente a la **Semana 14 ‚Äî Modelo kNN (Predicci√≥n de Retiro)**.

## Estimaci√≥n del modelo kNN

Ejecute el siguiente c√≥digo para estimar un modelo **k-Nearest Neighbors (kNN)** que prediga la **probabilidad de que un estudiante se retire del curso**, usando las variables explicativas relacionadas con esfuerzo y participaci√≥n.  ‚ö†Ô∏è No incluya la variable `aprueba` en el modelo.

```{webr-r}
##==: 1. Preparar Entorno

## Limpiar el entorno de trabajo
rm(list = ls())

## Instalar paquetes (solo si es necesario)
if (!require("pacman")) {install.packages("pacman") ; require("pacman")}

## Cargar librer√≠as
p_load(tidyverse)  # Manipulaci√≥n y visualizaci√≥n de datos
p_load(class)      # Implementaci√≥n del algoritmo kNN
p_load(caret)      # M√©tricas y matriz de confusi√≥n
p_load(pROC)       # Calcular la curva ROC y el AUC

##==: 2. Ingesta de Datos

## Leer datos
source("https://raw.githubusercontent.com/ba-in-r/01-slides/main/week-13/data/week-13.r")

## Preparar los datos
vars <- select(datos, horas_estudio:afinidad_estadistica)
datos_scaled <- as.data.frame(scale(vars))
datos_scaled$retira <- factor(datos$retira, levels = c(0, 1), labels = c("No", "S√≠"))

## Ver datos 
head(datos_scaled)
``` 

## Preguntas para el informe

**1. Comparaci√≥n entre modelos:**

‚Ä¢	¬øC√≥mo cambia la matriz de confusi√≥n al pasar de k = 5 a k = 10 y k = 20?

**2. Evaluaci√≥n de desempe√±o:**

‚Ä¢	Calcule la exactitud (accuracy) para cada modelo (k = 5, k = 10, k = 20).

‚Ä¢	¬øCu√°l de los tres modelos presenta la mayor exactitud?

**3. Curva ROC y poder discriminatorio**

‚Ä¢	¬øQu√© valor de AUC obtuvo para k = 5?

‚Ä¢	¬øQu√© indica este valor sobre la capacidad del modelo para distinguir entre estudiantes que se retiran y los que no?

‚Ä¢	¬øEsperar√≠as que el AUC mejore, empeore o se mantenga al aumentar k? ¬øPor qu√©?

**4. Reflexi√≥n final:** Si tuvieras que elegir uno de los tres modelos, ¬øcu√°l seleccionar√≠as y por qu√©?

::: callout-tip
üí° Entrega: Suba su documento con las respuestas a la plataforma Intu, en la actividad correspondiente a la Semana 14 ‚Äî Modelo kNN (Predicci√≥n de Retiro). Y suba el script con el que realiz√≥ el procedimiento. Recuerde que se evaluar√° la claridad de sus interpretaciones, la consistencia con los resultados del modelo y su capacidad para proponer acciones basadas en los hallazgos.
:::

